# -*- coding: utf-8 -*-
"""rev1 Limpieza Datos y Feature _Clustering Customer Personality Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MmblXVua7FRNMMk_FeWdgx0xsQTgh3rP

# Resumen del proyecto: Customer Personality Clustering

## Objetivo
Segmentar clientes en grupos homogéneos según su perfil económico y comportamiento de compra, con el fin de:
- Diseñar estrategias de marketing personalizadas
- Mejorar la fidelización
- Optimizar la asignación de recursos comerciales

---

## Proceso realizado

**1. Carga y exploración de datos**
- Dataset original de 2.240 clientes
- Limpieza y depuración:
  - Eliminación de duplicados
  - Agrupación de categorías raras en `Marital_Status`
  - Imputación de valores nulos en `Income`

**2. Ingeniería de características**
- Creación de variables:
  - `Age`: Edad actual
  - `Children`: Total de hijos en el hogar
  - `Total_Spent`: Gasto acumulado en los últimos 2 años
  - `Total_Purchases`: Total de compras en todos los canales
  - `Campaigns_Accepted`: Número de campañas aceptadas
  - `Customer_Since_Days`: Antigüedad del cliente en días

- Eliminación de columnas redundantes e identificadores

**3. Codificación y escalado**
- One-Hot Encoding en:
  - `Education`
  - `Marital_Status`
- Escalado estándar (`StandardScaler`) en todas las variables

**4. Clustering**
- Modelo utilizado: **KMeans**
- Número de clusters: **4**
- Asignación de segmento a cada cliente
- Evaluación de la calidad:
  - Silhouette Score: **0.119**
  - Distribución equilibrada de clientes por segmento

**5. Visualización**
- Reducción dimensional con PCA (2 componentes) y t-SNE (2 componentes)
- Gráficos de dispersión coloreados por segmento
- t-SNE permitió identificar mejor la distribución de grupos

**6. Guardado de artefactos**
- Modelo entrenado serializado (`kmeans_customer_segments.pkl`)
- Dataset final con segmentos (`customer_segments.csv`)

---

## Resultados y conclusiones

- El clustering logró identificar **4 segmentos diferenciados** de clientes.
- Cada grupo presenta patrones distintos en gasto total, antigüedad, ingresos y campañas aceptadas.
- Las visualizaciones de t-SNE mostraron una separación más clara que PCA.
- Este modelo permite:
  - Clasificar nuevos clientes en segmentos
  - Analizar la rentabilidad y perfil de cada grupo
  - Aplicar estrategias de marketing específicas

---
"""

#@title Paso 0 – Importación de librerías

# Manipulación de datos
import pandas as pd
import numpy as np

# Visualización
import seaborn as sns
import matplotlib.pyplot as plt

# Preprocesamiento
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.pipeline import Pipeline
from sklearn.base import BaseEstimator, TransformerMixin

# Clustering
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
from sklearn.manifold import TSNE

# Guardar y cargar modelos
import joblib

print("Librerías cargadas correctamente.")

#@title Paso 1 Cargar datos Customer Personality Analysis

df = pd.read_csv("Customer_Personality.csv",sep='\t')

#@title Paso 2: Limpieza y Feature Engineering

# Copia de seguridad por si se quiere conservar el original
df = df.copy()

# --- 1. Conversión de fechas y cálculo de antigüedad ---
df['Dt_Customer'] = pd.to_datetime(df['Dt_Customer'], dayfirst=True)
df['Customer_Since_Days'] = (df['Dt_Customer'].max() - df['Dt_Customer']).dt.days

# --- 2. Nuevas variables derivadas ---
df['Age'] = 2025 - df['Year_Birth']
df['Children'] = df['Kidhome'] + df['Teenhome']

# Gasto total
df['Total_Spent'] = df[['MntWines','MntFruits','MntMeatProducts',
                        'MntFishProducts','MntSweetProducts','MntGoldProds']].sum(axis=1)

# Compras totales
df['Total_Purchases'] = df[['NumWebPurchases','NumCatalogPurchases','NumStorePurchases']].sum(axis=1)

# Total campañas aceptadas
df['Campaigns_Accepted'] = df[['AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5']].sum(axis=1)

# --- 3. Limpieza de columnas ---
df.drop(columns=[
    'ID', 'Year_Birth', 'Dt_Customer',
    'Kidhome', 'Teenhome',
    'Z_CostContact', 'Z_Revenue',
    'AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5',
    'Response',
    'MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds',
    'NumWebPurchases','NumCatalogPurchases','NumStorePurchases'
], inplace=True)

# --- 4. Limpieza de datos ---
df.drop_duplicates(inplace=True)
df['Income'] = df['Income'].fillna(df['Income'].median())

# Agrupar valores extraños de estado civil
df['Marital_Status'] = df['Marital_Status'].replace({
    'Alone': 'Other', 'Absurd': 'Other', 'YOLO': 'Other'
})

print("Limpieza y feature engineering completados.")

#@title Gráfico de gasto medio por estado civil

sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
sns.barplot(
    data=df,
    x='Marital_Status',
    y='Total_Spent',
    estimator='mean',
    errorbar=None,
    hue='Marital_Status',  # evita warning de `palette`
    palette='muted',
    legend=False  # oculta la leyenda innecesaria
)

plt.title('Gasto Medio por Estado Civil', fontsize=16)
plt.xlabel('Estado Civil', fontsize=12)
plt.ylabel('Gasto Medio (€)', fontsize=12)
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

#@title Visualización Tabla
# Con la función head se muestra las 5 primeras filas del archivo.
df.head()

#@title Resumen estadistico general

df.describe().T

#@title Info de tipo de datos, nulos, etc.
df.info()

"""#**Leyenda con nuevas variables**
| Columna               | Tipo     | Descripción                                                                 |
|------------------------|----------|------------------------------------------------------------------------------|
| Education             | Categórica | Nivel educativo del cliente (e.g., Graduation, PhD, Master, etc.)           |
| Marital_Status        | Categórica | Estado civil del cliente                                                    |
| Income                | Numérica   | Ingreso anual familiar del cliente (en euros)                               |
| Recency               | Numérica   | Días desde la última compra del cliente                                     |
| NumDealsPurchases     | Numérica   | Número de compras realizadas con descuento                                  |
| NumWebVisitsMonth     | Numérica   | Número de visitas al sitio web en el último mes                             |
| Complain              | Binaria    | 1 = se quejó en los últimos 2 años, 0 = no se quejó                         |
| Customer_Since_Days   | Numérica   | Antigüedad del cliente en días desde su alta en la empresa                  |
| Age                   | Numérica   | Edad del cliente (calculada como 2025 - Year_Birth)                         |
| Children              | Numérica   | Número total de hijos (Kidhome + Teenhome)                                  |
| Total_Spent           | Numérica   | Gasto total acumulado en productos (vino, carne, frutas, oro, etc.)         |
| Total_Purchases       | Numérica   | Número total de compras por cualquier canal                                 |
| Campaigns_Accepted    | Numérica   | Número total de campañas promocionales aceptadas (de 0 a 5)                 |

"""

#@title Paso 3: Codificación de variables categóricas + Escalado

# 1️ Codificación One-Hot de variables categóricas
df_encoded = pd.get_dummies(
    df,
    columns=['Education', 'Marital_Status'],
    drop_first=True
)

print("Codificación completada.")
print(f"Columnas resultantes: {df_encoded.columns.tolist()}")

# 2️ Escalado de todas las variables

scaler = StandardScaler()
df_scaled = pd.DataFrame(
    scaler.fit_transform(df_encoded),
    columns=df_encoded.columns
)

print("Escalado completado.")

# 3️ Verificación de la forma del dataset final
print(f"Dimensiones finales del dataset: {df_scaled.shape}")

# 4️ Vista previa
df_scaled.head()

#@title Paso 4: Entrenamiento del clustering y análisis de segmentos (corregido)

# 1 Entrenar el modelo
kmeans = KMeans(n_clusters=4, random_state=42)
kmeans.fit(df_scaled)

# 2️ Asignar segmentos
df["Segment"] = kmeans.labels_

print(" Clustering completado.")

# 3️ Silhouette Score
sil_score = silhouette_score(df_scaled, kmeans.labels_)
print(f" Silhouette Score: {sil_score:.3f}")

# 4️ Resumen de variables numéricas solamente
numerical_cols = ['Income', 'Recency', 'NumDealsPurchases', 'NumWebVisitsMonth',
                  'Complain', 'Customer_Since_Days', 'Age', 'Children',
                  'Total_Spent', 'Total_Purchases', 'Campaigns_Accepted']

segment_summary = df.groupby("Segment")[numerical_cols].mean().round(1)
print("\n Resumen de cada segmento (variables numéricas):")
display(segment_summary)

# 5️ Distribución de clientes
counts = df["Segment"].value_counts().sort_index()
print("\n Número de clientes por segmento:")
print(counts)

# 6️ Vista previa
df.head()

#@title Paso 5: Reducción dimensional con PCA y visualización de clusters

# 1️ Reducir a 2 dimensiones
pca = PCA(n_components=2, random_state=42)
pca_components = pca.fit_transform(df_scaled)

# 2️ Crear DataFrame con componentes y segmentos
pca_df = pd.DataFrame(pca_components, columns=["PC1", "PC2"])
pca_df["Segment"] = df["Segment"]

# 3️ Visualización
plt.figure(figsize=(10,6))
sns.scatterplot(
    x="PC1",
    y="PC2",
    hue="Segment",
    palette="tab10",
    data=pca_df,
    alpha=0.7,
    s=60
)
plt.title("Visualización PCA de los clusters")
plt.xlabel("Componente Principal 1")
plt.ylabel("Componente Principal 2")
plt.legend(title="Segmento")
plt.show()

# 4️ Varianza explicada
explained_variance = pca.explained_variance_ratio_.sum()
print(f" Porcentaje de varianza explicada por las 2 componentes: {explained_variance:.2%}")

#@title Paso 6: Guardar modelo y dataset con segmentos
# Guardar el modelo KMeans
#import joblib

joblib.dump(kmeans, "kmeans_customer_segments.pkl")
print(" Modelo guardado como 'kmeans_customer_segments.pkl'.")

# Guardar el dataset con segmentos
df.to_csv("customer_segments.csv", index=False)
print(" Dataset guardado como 'customer_segments.csv'.")

#@title Paso 7: Visualización con t-SNE

tsne = TSNE(n_components=2, random_state=42, perplexity=40, max_iter=300)
tsne_components = tsne.fit_transform(df_scaled)

tsne_df = pd.DataFrame(tsne_components, columns=["TSNE1", "TSNE2"])
tsne_df["Segment"] = df["Segment"]

plt.figure(figsize=(10,6))
sns.scatterplot(
    x="TSNE1",
    y="TSNE2",
    hue="Segment",
    palette="tab10",
    data=tsne_df,
    alpha=0.7,
    s=60
)
plt.title("Visualización t-SNE de los clusters")
plt.show()

#@title Paso 8: Preparar predicciones en nuevos datos

# Ejemplo: Predecir el segmento de un nuevo cliente
nuevo_cliente = df_scaled.iloc[[0]]
segmento_predicho = kmeans.predict(nuevo_cliente)[0]
print(f"Segmento asignado al nuevo cliente: {segmento_predicho}")

#@title Paso 9: Tabla resumen de medias por segmento
vars_bar = [
    'Income',
    'Age',
    'Total_Spent',
    'Total_Purchases',
    'Customer_Since_Days',
    'Children',
    'Recency'
]

# Crear tabla resumen
tabla_resumen = df.groupby('Cluster_Nombre_Abrev')[vars_bar].mean().round(1)

print(" Tabla de medias por segmento:")
display(tabla_resumen)

#@title Paso 10: Gráficos de barras con medias reales

# Reset index para graficar
cluster_means = tabla_resumen.reset_index()

cols = 3
rows = -(-len(vars_bar) // cols)
fig, axes = plt.subplots(rows, cols, figsize=(cols * 5, rows * 4))
axes = axes.flatten()

for i, var in enumerate(vars_bar):
    sns.barplot(
        data=cluster_means,
        x='Cluster_Nombre_Abrev',
        y=var,
        hue='Cluster_Nombre_Abrev',
        palette='Set2',
        legend=False,
        ax=axes[i]
    )
    axes[i].set_title(var, fontsize=12)
    axes[i].set_ylabel('Media')
    axes[i].set_xlabel('Segmento')
    axes[i].tick_params(axis='x', rotation=15)
    axes[i].grid(True, axis='y')

# Quitar subgráficos vacíos si sobran
for j in range(i + 1, len(axes)):
    fig.delaxes(axes[j])

plt.tight_layout()
plt.show()

#@title Paso 11 Radar Plot comparativo de segmentos

# Normalizar cada variable 0-1 para radar
radar_data = tabla_resumen.copy()
for col in radar_data.columns:
    min_ = radar_data[col].min()
    max_ = radar_data[col].max()
    radar_data[col] = (radar_data[col] - min_) / (max_ - min_)

# Variables
labels = radar_data.columns
n_vars = len(labels)

# Ángulos
angles = np.linspace(0, 2 * np.pi, n_vars, endpoint=False).tolist()
angles += angles[:1]

# Crear figura
fig, ax = plt.subplots(figsize=(8,8), subplot_kw=dict(polar=True))

# Plotear cada segmento
for idx, row in radar_data.iterrows():
    values = row.tolist()
    values += values[:1]
    ax.plot(angles, values, label=idx)
    ax.fill(angles, values, alpha=0.25)

# Ajustar etiquetas
ax.set_xticks(angles[:-1])
ax.set_xticklabels(labels, fontsize=11)
ax.set_yticks([0.2,0.4,0.6,0.8])
ax.set_yticklabels(['20%','40%','60%','80%'])
ax.set_title('Comparación de segmentos (Radar plot)', size=12, pad=40)
ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
plt.show()